# 대규모 서비스를 지탱하는 기술

## 베이지안 필터 원리

* 나이브 베이즈라는 알고리즘을 사용.

## 나이브 베이즈

* 베이즈 정리라는 공식을 기반으로 핢.
* P(B|A) = P(A|B) P(B) / P(A)

### 예시

P(C|D) : 특정 문서 D가 확률적으로 어떤 카테고리 C에 속하는가.

#### 변형

P(D|C) P(C) / P(D)

* P(D) : 분모로서 문서 D가 발생할 확률로, 모든 카테고리에 동일한 값을 적용해서 비교하기 때문에 생략 가능.
* P(C) : 카테고리가 출현할 확률. 여러 데이터가 어떤 카테고리로 분류되었는지 횟수를 저장해서 계산.
* P(D|C)
    * 문서 D는 임의의 단어 W가 연속해서 출현하는 것으로 간주. P(W1|C), P(W2|C)...
    * D를 각 단어로 분할해서 각 단어마다 어떤 카테고리로 분류됐는지 횟수를 저장해서 P(D|C)의 근사값을 구함.

### 결론

* 정해 데이터가 사용된 횟수, 단어 출련횟수와 같은 수치를 저장해두면 확률을 계산해서 카테고리 추정 가능.

## 스펠링 오류 수정 기능의 구현 방법

* 기계학습을 위한 대규모 데이터가 없다면, 사전 데이터를 활용.

### 기능의 순서

1. 필요한 사전 데이터 구성.
2. 입력 데이터와 사전의 어구 사이의 편집 거리를 구해서 '오류 정도'를 구함.
    * (대규모 서비스, 대규모 서비수) -> 1
    * (대규 서비스, 대규모 서비스) -> 1)
    * (소규모 서비쓰, 대규모 서비스) -> 2
3. 오류 정도를 기준으로 단어군 후보를 구함.
4. 정해 후보중에서 단어 이용빈도가 큰 순으로 정렬.
5. 이용빈도가 높은 단어를 제시.



