# 대규모 서비스를 지탱하는 기술

## 파일 전체가 아닌 페이지 단위의 캐시

디스크에서 데이터를 읽어낼 때는 4kb 단위의 페이지로 데이터를 읽어내서 메모리에 캐시해둔다. 이렇게 하면 파일 전체가 아니라 파일의 필요한 일부분만 읽어서 캐싱할 수 있다.

만약 메모리가 2GB인데 사용하려고 하는 파일이 총 4GB라고 하면, 이 파일 전체를 메모리에 올려서 사용하기는 불가능할 것이다. 그래서 실제 필요한 데이터만 페이지 단위로 조금씩 메모리에 올려서 캐싱하고 사용한다.

생각해보면 최근에 나온 게임들은 수십 GB가 되는데, 메모리는 가정용 PC에서 보통 16GB나 많으면 32GB 정도밖에 되지 않는다. 게임 하나가 전체 메모리 용량보다 큰데 이 게임 외에 브라우저나 여러 다른 애플리케이션도 함께 실행시켜서 사용한다. 그 이유는 바로 애플리케이션 전체를 메모리에 올리는 것이 아닌 일부분만 페이지단위로 메모리에 올려서 실행시키기 때문에 가능하다.

## LRU(Least Recently Used)

만약 메모리가 2GB인데, 4GB의 파일 전체 데이터가 필요하다면 메모리가 꽉 차기 전까지는 계속 빈 공간에 캐시를 적용할 것이다. 그러나 메모리가 가득 차면 가장 오래된 캐시를 지우고 새롭게 읽어들인 데이터를 캐시한다. 이런 특성으로 인해 DB를 계속 구동시키다보면 자주 사용하는 데이터들로 캐시가 최적화되어서 I/O가 줄어들 수 있다.

## 리눅스가 캐시를 하는 방법

리눅스는 i노드라고 하는 파일을 식별하는 번호와 파일의 위치를 나타내는 오프셋이라고 하는 2가지 값을 키로 캐싱한다. 그래서 특정 파일(i노드)의 특정 위치(오프셋)를 지정해서 파일의 일부분만 캐싱할 수 있는 것이다.

그리고 이 키와 페이지를 커널에서는 Radix Tree라는 데이터 구조를 이용해서 최적화하기 때문에 파일의 크기가 커도 캐시를 찾는데 빠른 탐색 속도를 유지할 수 있다.

## 리눅스에서 현재 메로리 상태 확인

sar -r 옵션으로 현재 메모리의 상태를 확인할 수 있으며, 만약 "sar -r 1"을 입력하면 1초 단위로 확인할 수 있다. 

### kbcached(kilo byte chaced)

출력되는 내용중에 kbcached가 있는데 얼마나 캐시를 하고 있는지를 나타낸다. 만약 이 영역이 너무 높아서 메모리가 부족해 보이더라도 페이지 단위로 OS가 조금씩 데이터를 캐시하고 있으며, 오래된 캐시는 파기하기 때문에 문제가 발생하진 않을 것이다.

## 메모리 용량을 늘려서 I/O 부하를 해결

결국 메모리 용량이 높으면 높을수록 디스크의 데이터를 많이 캐싱할 수 있기 때문에 그만큼 디스크 액세스 빈도를 줄일 수 있음을 알 수 있다.


